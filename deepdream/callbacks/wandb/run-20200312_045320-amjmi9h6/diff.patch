diff --git a/Examples/__init__.py b/Examples/__init__.py
new file mode 100644
index 0000000..3cc5335
--- /dev/null
+++ b/Examples/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 14:48
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/Examples/demo.py b/Examples/demo.py
new file mode 100644
index 0000000..38e48c3
--- /dev/null
+++ b/Examples/demo.py
@@ -0,0 +1,51 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : demo
+# @Time         : 2020-02-12 20:17
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+import numpy as np
+from sklearn.datasets import make_classification
+from torch import nn
+import torch.nn.functional as F
+
+from skorch import NeuralNetClassifier
+
+
+X, y = make_classification(1000, 20, n_informative=10, random_state=0)
+X = X.astype(np.float32)
+y = y.astype(np.int64)
+
+class MyModule(nn.Module):
+    def __init__(self, num_units=10, nonlin=F.relu):
+        super(MyModule, self).__init__()
+
+        self.dense0 = nn.Linear(20, num_units)
+        self.nonlin = nonlin
+        self.dropout = nn.Dropout(0.5)
+        self.dense1 = nn.Linear(num_units, 10)
+        self.output = nn.Linear(10, 2)
+
+    def forward(self, X, **kwargs):
+        X = self.nonlin(self.dense0(X))
+        X = self.dropout(X)
+        X = F.relu(self.dense1(X))
+        X = F.softmax(self.output(X), dim=-1)
+        return X
+
+
+net = NeuralNetClassifier(
+    MyModule,
+    max_epochs=10,
+    lr=0.1,
+    # Shuffle training data on each epoch
+    iterator_train__shuffle=True,
+)
+
+net.fit()
+net.fit_loop()
\ No newline at end of file
diff --git a/README.md b/README.md
new file mode 100644
index 0000000..f71f4c4
--- /dev/null
+++ b/README.md
@@ -0,0 +1,438 @@
+<h1 align = "center">:rocket: DataScience :facepunch:</h1>
+
+---
+- [mlcrate][https://github.com/mxbi/mlcrate]
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/README_1200x800.gif">
+</p>
+
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/coversmall_alt.png">
+  <br/>
+</p>
+
+# data-science-ipython-notebooks
+
+## Index
+
+* [deep-learning](#deep-learning)
+    * [tensorflow](#tensor-flow-tutorials)
+    * [theano](#theano-tutorials)
+    * [keras](#keras-tutorials)
+    * [caffe](#deep-learning-misc)
+* [scikit-learn](#scikit-learn)
+* [statistical-inference-scipy](#statistical-inference-scipy)
+* [pandas](#pandas)
+* [matplotlib](#matplotlib)
+* [numpy](#numpy)
+* [python-data](#python-data)
+* [kaggle-and-business-analyses](#kaggle-and-business-analyses)
+* [spark](#spark)
+* [mapreduce-python](#mapreduce-python)
+* [amazon web services](#aws)
+* [command lines](#commands)
+* [misc](#misc)
+* [notebook-installation](#notebook-installation)
+* [credits](#credits)
+* [contributing](#contributing)
+* [contact-info](#contact-info)
+* [license](#license)
+
+<br/>
+<p align="center">
+  <img src="http://i.imgur.com/ZhKXrKZ.png">
+</p>
+
+## deep-learning
+
+IPython Notebook(s) demonstrating deep learning functionality.
+
+<br/>
+<p align="center">
+  <img src="https://avatars0.githubusercontent.com/u/15658638?v=3&s=100">
+</p>
+
+### tensor-flow-tutorials
+
+Additional TensorFlow tutorials:
+
+* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)
+* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)
+* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)
+* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [tsf-basics](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |
+| [tsf-linear](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |
+| [tsf-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |
+| [tsf-nn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |
+| [tsf-alex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |
+| [tsf-cnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |
+| [tsf-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |
+| [tsf-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |
+| [tsf-gpu](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |
+| [tsf-gviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |
+| [tsf-lviz](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |
+
+### tensor-flow-exercises
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [tsf-not-mnist](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |
+| [tsf-fully-connected](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |
+| [tsf-regularization](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |
+| [tsf-convolutions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |
+| [tsf-word2vec](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |
+| [tsf-lstm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |
+
+<br/>
+<p align="center">
+  <img src="http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png">
+</p>
+
+### theano-tutorials
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [theano-intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |
+| [theano-scan](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |
+| [theano-logistic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |
+| [theano-rnn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |
+| [theano-mlp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |
+
+<br/>
+<p align="center">
+  <img src="http://i.imgur.com/L45Q8c2.jpg">
+</p>
+
+### keras-tutorials
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |
+| [setup](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/0.%20Preamble.ipynb) | Learn about the tutorial goals and how to set up your Keras environment. |
+| [intro-deep-learning-ann](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |
+| [theano](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |
+| [keras-otto](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |
+| [ann-mnist](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/1.4%20%28Extra%29%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |
+| [conv-nets](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |
+| [conv-net-1](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |
+| [conv-net-2](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |
+| [keras-models](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |
+| [auto-encoders](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.1%20Unsupervised%20Learning%20-%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |
+| [rnn-lstm](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.2%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |
+| [lstm-sentence-gen](https://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/keras-tutorial/3.3%20%28Extra%29%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |
+
+### deep-learning-misc
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [deep-dream](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png">
+</p>
+
+## scikit-learn
+
+IPython Notebook(s) demonstrating scikit-learn functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [intro](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
+| [knn](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |
+| [linear-reg](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |
+| [svm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |
+| [random-forest](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |
+| [k-means](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |
+| [pca](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |
+| [gmm](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |
+| [validation](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png">
+</p>
+
+## statistical-inference-scipy
+
+IPython Notebook(s) demonstrating statistical inference with SciPy functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |
+| [effect-size](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |
+| [sampling](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |
+| [hypothesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png">
+</p>
+
+## pandas
+
+IPython Notebook(s) demonstrating pandas functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [pandas](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |
+| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |
+| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |
+| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |
+| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |
+| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |
+| [Missing-Values](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |
+| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |
+| [Concat-And-Append](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |
+| [Merge-and-Join](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |
+| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |
+| [Pivot-Tables](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |
+| [Working-With-Strings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |
+| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |
+| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png">
+</p>
+
+## matplotlib
+
+IPython Notebook(s) demonstrating matplotlib functionality.
+
+| Notebook | Description |
+|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [matplotlib](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |
+| [matplotlib-applied](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |
+| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |
+| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |
+| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |
+| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |
+| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |
+| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |
+| [Customizing-Legends](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |
+| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |
+| [Multiple-Subplots](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |
+| [Text-and-Annotation](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |
+| [Customizing-Ticks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |
+| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |
+| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |
+| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |
+| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png">
+</p>
+
+## numpy
+
+IPython Notebook(s) demonstrating NumPy functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [numpy](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |
+| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |
+| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |
+| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |
+| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |
+| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |
+| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |
+| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |
+| [Fancy-Indexing](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |
+| [Sorting](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |
+| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png">
+</p>
+
+## python-data
+
+IPython Notebook(s) demonstrating Python functionality geared towards data analysis.
+
+| Notebook | Description |
+|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|
+| [data structures](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |
+| [data structure utilities](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |
+| [functions](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |
+| [datetime](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |
+| [logging](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |
+| [pdb](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |
+| [unit tests](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png">
+</p>
+
+## kaggle-and-business-analyses
+
+IPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.
+
+| Notebook | Description |
+|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
+| [titanic](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |
+| [churn-analysis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png">
+</p>
+
+## spark
+
+IPython Notebook(s) demonstrating spark and HDFS functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
+| [spark](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |
+| [hdfs](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png">
+</p>
+
+## mapreduce-python
+
+IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
+| [mapreduce-python](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|
+
+<br/>
+
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png">
+</p>
+
+## aws
+
+IPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.
+
+
+Also check out:
+
+* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).
+* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.
+
+| Notebook | Description |
+|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [boto](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |
+| [s3cmd](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |
+| [s3distcp](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |
+| [s3-parallel-put](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |
+| [redshift](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |
+| [kinesis](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |
+| [lambda](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |
+
+<br/>
+<p align="center">
+  <img src="https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png">
+</p>
+
+## commands
+
+IPython Notebook(s) demonstrating various command lines for Linux, Git, etc.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [linux](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|
+| [anaconda](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |
+| [ipython notebook](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |
+| [git](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |
+| [ruby](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |
+| [jekyll](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |
+| [pelican](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |
+| [django](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).
+
+## misc
+
+IPython Notebook(s) demonstrating miscellaneous functionality.
+
+| Notebook | Description |
+|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+| [regex](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|
+[algorithmia](http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|
+
+## notebook-installation
+
+### anaconda
+
+Anaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.
+
+Follow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).
+
+### dev-setup
+
+For detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.
+
+### running-notebooks
+
+To view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)
+
+    $ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git
+    $ cd data-science-ipython-notebooks
+    $ jupyter notebook
+
+Notebooks tested with Python 2.7.x.
+
+## credits
+
+* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney
+* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas
+* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas
+* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel
+* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey
+* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien
+* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital
+* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz
+* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen
+* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla
+* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem
+* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio
+* [Kaggle](https://www.kaggle.com/)
+* [Yhat Blog](http://blog.yhat.com/)
+
+## contributing
+
+Contributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/donnemartin/data-science-ipython-notebooks/issues).
+
+## contact-info
+
+Feel free to contact me to discuss any issues, questions, or comments.
+
+* Email: [donne.martin@gmail.com](mailto:donne.martin@gmail.com)
+* Twitter: [@donne_martin](https://twitter.com/donne_martin)
+* GitHub: [donnemartin](https://github.com/donnemartin)
+* LinkedIn: [donnemartin](https://www.linkedin.com/in/donnemartin)
+* Website: [donnemartin.com](http://donnemartin.com)
+
+## license
+
+This repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties.
+
+The content developed by Donne Martin is distributed under the following license:
+
+*I am providing code and resources in this repository to you under an open source license.  Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).*
+
+    Copyright 2015 Donne Martin
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
diff --git a/Tutorials/__init__.py b/Tutorials/__init__.py
new file mode 100644
index 0000000..eb2f9df
--- /dev/null
+++ b/Tutorials/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2020-02-12 00:00
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/Require.md b/deeptricks/Require.md
new file mode 100644
index 0000000..1dead76
--- /dev/null
+++ b/deeptricks/Require.md
@@ -0,0 +1,3 @@
+- Jack
+- https://www.kaggle.com/mmueller/f1-score-expectation-maximization-in-o-n
+https://www.kaggle.com/rsakata/gmm-with-target-perfect-pred-random-shuffle
\ No newline at end of file
diff --git a/deeptricks/__init__.py b/deeptricks/__init__.py
new file mode 100644
index 0000000..5b77207
--- /dev/null
+++ b/deeptricks/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 14:36
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/activations/__init__.py b/deeptricks/activations/__init__.py
new file mode 100644
index 0000000..89f7f24
--- /dev/null
+++ b/deeptricks/activations/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 15:21
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/backend.py b/deeptricks/backend.py
new file mode 100644
index 0000000..c3c32f7
--- /dev/null
+++ b/deeptricks/backend.py
@@ -0,0 +1,32 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : backend
+# @Time         : 2019-09-10 15:16
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+# import tensorflow as tf
+#
+# from tensorflow.python import keras
+#
+# utils = keras.utils
+# activations = keras.activations
+# applications = keras.applications
+# backend = keras.backend
+# datasets = keras.datasets
+# engine = keras.engine
+# layers = keras.layers
+# preprocessing = keras.preprocessing
+# wrappers = keras.wrappers
+# callbacks = keras.callbacks
+# constraints = keras.constraints
+# initializers = keras.initializers
+# metrics = keras.metrics
+# models = keras.models
+# losses = keras.losses
+# optimizers = keras.optimizers
+# regularizers = keras.regularizers
diff --git a/deeptricks/callbacks/__init__.py b/deeptricks/callbacks/__init__.py
new file mode 100644
index 0000000..d5801fd
--- /dev/null
+++ b/deeptricks/callbacks/__init__.py
@@ -0,0 +1,28 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : Python.
+# @File         : __init__.py
+# @Time         : 2020-03-12 12:48
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+import wandb
+from wandb.keras import WandbCallback
+
+# torch
+# Initialize wandb
+wandb.init(project="Keraser")
+config = wandb.config
+
+# Track hyperparameters
+config.dropout = 0.2
+config.hidden_layer_size = 128
+config.layer_1_size = 16
+config.layer_2_size = 32
+config.learn_rate = 0.01
+config.decay = 1e-6
+config.momentum = 0.9
+config.epochs = 8
diff --git a/deeptricks/cv/KerasCV.py b/deeptricks/cv/KerasCV.py
new file mode 100644
index 0000000..b576dd0
--- /dev/null
+++ b/deeptricks/cv/KerasCV.py
@@ -0,0 +1,92 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : tql-Python.
+# @File         : KerasOOF
+# @Time         : 2019-07-01 22:44
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  :
+
+
+import time
+import numpy as np
+import pandas as pd
+from sklearn.model_selection import StratifiedKFold, KFold
+from sklearn.metrics import roc_auc_score
+
+
+class KerasCV(object):
+    """cross_val_predict"""
+
+    def __init__(self, create_estimator, batch_size=128, epochs=10, callbacks=None, cv=5, random_state=None):
+        self.estimators = [create_estimator() for _ in range(cv)]
+        self.batch_size = batch_size
+        self.epochs = epochs
+        self.callbacks = callbacks
+        self._kf = StratifiedKFold(cv, True, random_state)
+        self._num_preds = cv
+
+    def fit(self, X, y, X_test, feval=roc_auc_score):
+        """
+        :param X:
+        :param y:
+        :param X_test:
+        :param feval:
+        :return:
+        """
+        self.oof_train = np.zeros(len(X))
+        self.oof_test = np.zeros((len(X_test), self._num_preds))
+        for (n_fold, (train_index, valid_index)), estimator in zip(enumerate(self._kf.split(X, y)), self.estimators):
+            print(f"\n\033[94mFold {n_fold + 1} started at {time.ctime()}\033[0m")
+            X_train, y_train = X[train_index], y[train_index]
+            X_valid, y_valid = X[valid_index], y[valid_index]
+            # eval_set = [(X_train, y_train), (X_valid, y_valid)]
+            estimator.fit(X_train, y_train,
+                          validation_data=(X_valid, y_valid),
+                          batch_size=self.batch_size,
+                          epochs=self.epochs,
+                          callbacks=self.callbacks)
+
+            ########################################################################
+            # 
+            self.oof_train[valid_index] = estimator.predict(X_valid)[:, -1]  # num_sample * 1
+            self.oof_test[:, n_fold] = estimator.predict(X_test)[:, -1]
+            ########################################################################
+
+        #   oof
+        self.oof_test_rank = pd.DataFrame(self.oof_test).rank().mean(1) / len(self.oof_test)
+        self.oof_test = self.oof_test.mean(1)
+
+        #   oof 
+        if feval:
+            score = feval(y, self.oof_train)
+            print(f"\n\033[94mCV Sorce: {score} ended at {time.ctime()}\033[0m")
+            return score
+
+    def oof_save(self, file='./oof_train_and_test.csv'):
+        assert isinstance(file, str)
+        _ = np.append(self.oof_train, self.oof_test)
+        pd.DataFrame(_, columns='oof_train_and_test').to_csv(file, index=False)
+
+
+if __name__ == '__main__':
+    from tensorflow.python.keras.layers import Dense
+    from tensorflow.python.keras.models import Sequential
+
+
+    def create_model():
+        """from tensorflow.python.keras.models import clone_and_build_model"""
+        model = Sequential()
+        model.add(Dense(12, input_dim=20, kernel_initializer="uniform", activation="relu"))
+        model.add(Dense(8, kernel_initializer="uniform", activation="relu"))
+        model.add(Dense(1, kernel_initializer="uniform", activation="sigmoid"))
+        model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])
+        return model
+
+
+    oof = KerasCV(create_estimator=create_model)
+    from sklearn.datasets import make_classification
+
+    X, y = make_classification(10000, shift=0.1)
+    oof.fit(X, y, X)
diff --git a/deeptricks/cv/__init__.py b/deeptricks/cv/__init__.py
new file mode 100644
index 0000000..97fbd28
--- /dev/null
+++ b/deeptricks/cv/__init__.py
@@ -0,0 +1,12 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-15 12:16
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+from .KerasCV import KerasCV
diff --git a/deeptricks/dateset/DataLoader.py b/deeptricks/dateset/DataLoader.py
new file mode 100644
index 0000000..7277f5b
--- /dev/null
+++ b/deeptricks/dateset/DataLoader.py
@@ -0,0 +1,33 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : DataLoader
+# @Time         : 2019-10-21 13:01
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+import tensorflow as tf
+
+"""
+https://www.cnblogs.com/gengyi/p/11107492.html
+https://tensorflow.google.cn/guide/data?hl=zh_cn
+https://cs230-stanford.github.io/tensorflow-input-data.html#shuffle-and-repeat
+
+tf.data.Dataset.zip
+"""
+
+
+class DataGenerator(object):
+
+    def __init__(self, data_type='train', batchsize=128):
+        self.data_type = data_type
+        self.batchsize = batchsize
+
+    def from_numpy(self, tensors, buffer_size=10000, seed=666):
+        dataset = tf.data.Dataset.from_tensor_slices(tensors).batch(self.batchsize)
+        if self.data_type in ('train', 'valid'):
+            dataset = dataset.shuffle(buffer_size, seed)
+
+        return dataset
diff --git a/deeptricks/dateset/__init__.py b/deeptricks/dateset/__init__.py
new file mode 100644
index 0000000..71dc354
--- /dev/null
+++ b/deeptricks/dateset/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-10-21 13:00
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/dateset/utils.py b/deeptricks/dateset/utils.py
new file mode 100644
index 0000000..11c45b0
--- /dev/null
+++ b/deeptricks/dateset/utils.py
@@ -0,0 +1,17 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : utils
+# @Time         : 2020-02-19 11:46
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+import pandas as pd
+
+
+def libsvm2df(file, max_index=16, batch_size=128):
+    dic = dict(zip(range(max_index), [0] * max_index))
+    fn = lambda r: {**dic, **eval("{0:" + r.replace(' ', ',') + "}")}
+    df_iter = pd.read_csv(file, names='r', iterator=True)
+    yield pd.DataFrame(df_iter.get_chunk(batch_size)['r'].map(fn).values.tolist())
diff --git a/deeptricks/demo.py b/deeptricks/demo.py
new file mode 100644
index 0000000..5b1f103
--- /dev/null
+++ b/deeptricks/demo.py
@@ -0,0 +1,21 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : demo
+# @Time         : 2019-09-10 15:17
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+from yaml import safe_load
+
+print(safe_load(open('./files.yml')))
+
+from tensorflow.python.keras.preprocessing import text
+from tensorflow.python.keras.preprocessing.text import hashing_trick
+
+
+text.Tokenizer
+
+from tensorflow.keras.preprocessing import text
\ No newline at end of file
diff --git a/deeptricks/deploy/README.md b/deeptricks/deploy/README.md
new file mode 100644
index 0000000..261b015
--- /dev/null
+++ b/deeptricks/deploy/README.md
@@ -0,0 +1,6 @@
+- seldon_core
+- [m2cgen][1]
+
+
+---
+[1]: https://github.com/BayesWitnesses/m2cgen
\ No newline at end of file
diff --git a/deeptricks/deploy/__init__.py b/deeptricks/deploy/__init__.py
new file mode 100644
index 0000000..f946d0e
--- /dev/null
+++ b/deeptricks/deploy/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-10-17 18:57
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/files.yml b/deeptricks/files.yml
new file mode 100644
index 0000000..5a9094b
--- /dev/null
+++ b/deeptricks/files.yml
@@ -0,0 +1 @@
+a.a: 1
\ No newline at end of file
diff --git a/deeptricks/layers/__init__.py b/deeptricks/layers/__init__.py
new file mode 100644
index 0000000..5189e96
--- /dev/null
+++ b/deeptricks/layers/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 15:22
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/learn_rate/__init__.py b/deeptricks/learn_rate/__init__.py
new file mode 100644
index 0000000..676bf9b
--- /dev/null
+++ b/deeptricks/learn_rate/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 21:59
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/learn_rate/clr/CyclicLR.py b/deeptricks/learn_rate/clr/CyclicLR.py
new file mode 100644
index 0000000..afc500d
--- /dev/null
+++ b/deeptricks/learn_rate/clr/CyclicLR.py
@@ -0,0 +1,144 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : clr_callback
+# @Time         : 2019-09-10 22:23
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+from tensorflow.python.keras.callbacks import *
+
+
+class CyclicLR(Callback):
+    """This callback implements a cyclical learning rate policy (CLR).
+    The method cycles the learning rate between two boundaries with
+    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).
+    The amplitude of the cycle can be scaled on a per-iteration or
+    per-cycle basis.
+    This class has three built-in policies, as put forth in the paper.
+    "triangular":
+        A basic triangular cycle w/ no amplitude scaling.
+    "triangular2":
+        A basic triangular cycle that scales initial amplitude by half each cycle.
+    "exp_range":
+        A cycle that scales initial amplitude by gamma**(cycle iterations) at each
+        cycle iteration.
+    For more detail, please see paper.
+
+    # Example
+        ```python
+            clr = CyclicLR(base_lr=0.001, max_lr=0.006,
+                                step_size=2000., mode='triangular')
+            model.fit(X_train, Y_train, callbacks=[clr])
+        ```
+
+    Class also supports custom scaling functions:
+        ```python
+            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))
+            clr = CyclicLR(base_lr=0.001, max_lr=0.006,
+                                step_size=2000., scale_fn=clr_fn,
+                                scale_mode='cycle')
+            model.fit(X_train, Y_train, callbacks=[clr])
+        ```
+    # Arguments
+        base_lr: initial learning rate which is the
+            lower boundary in the cycle.
+        max_lr: upper boundary in the cycle. Functionally,
+            it defines the cycle amplitude (max_lr - base_lr).
+            The lr at any cycle is the sum of base_lr
+            and some scaling of the amplitude; therefore
+            max_lr may not actually be reached depending on
+            scaling function.
+        step_size: number of training iterations per
+            half cycle. Authors suggest setting step_size
+            2-8 x training iterations in epoch.
+        mode: one of {triangular, triangular2, exp_range}.
+            Default 'triangular'.
+            Values correspond to policies detailed above.
+            If scale_fn is not None, this argument is ignored.
+        gamma: constant in 'exp_range' scaling function:
+            gamma**(cycle iterations)
+        scale_fn: Custom scaling policy defined by a single
+            argument lambda function, where
+            0 <= scale_fn(x) <= 1 for all x >= 0.
+            mode paramater is ignored
+        scale_mode: {'cycle', 'iterations'}.
+            Defines whether scale_fn is evaluated on
+            cycle number or cycle iterations (training
+            iterations since start of cycle). Default is 'cycle'.
+    """
+
+    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',
+                 gamma=1., scale_fn=None, scale_mode='cycle'):
+        super(CyclicLR, self).__init__()
+
+        self.base_lr = base_lr
+        self.max_lr = max_lr
+        self.step_size = step_size
+        self.mode = mode
+        self.gamma = gamma
+        if scale_fn == None:
+            if self.mode == 'triangular':
+                self.scale_fn = lambda x: 1.
+                self.scale_mode = 'cycle'
+            elif self.mode == 'triangular2':
+                self.scale_fn = lambda x: 1 / (2. ** (x - 1))
+                self.scale_mode = 'cycle'
+            elif self.mode == 'exp_range':
+                self.scale_fn = lambda x: gamma ** (x)
+                self.scale_mode = 'iterations'
+        else:
+            self.scale_fn = scale_fn
+            self.scale_mode = scale_mode
+        self.clr_iterations = 0.
+        self.trn_iterations = 0.
+        self.history = {}
+
+        self._reset()
+
+    def _reset(self, new_base_lr=None, new_max_lr=None,
+               new_step_size=None):
+        """Resets cycle iterations.
+        Optional boundary/step size adjustment.
+        """
+        if new_base_lr != None:
+            self.base_lr = new_base_lr
+        if new_max_lr != None:
+            self.max_lr = new_max_lr
+        if new_step_size != None:
+            self.step_size = new_step_size
+        self.clr_iterations = 0.
+
+    def clr(self):
+        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))
+        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)
+        if self.scale_mode == 'cycle':
+            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)
+        else:
+            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(
+                self.clr_iterations)
+
+    def on_train_begin(self, logs={}):
+        logs = logs or {}
+
+        if self.clr_iterations == 0:
+            K.set_value(self.model.optimizer.lr, self.base_lr)
+        else:
+            K.set_value(self.model.optimizer.lr, self.clr())
+
+    def on_batch_end(self, epoch, logs=None):
+
+        logs = logs or {}
+        self.trn_iterations += 1
+        self.clr_iterations += 1
+
+        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))
+        self.history.setdefault('iterations', []).append(self.trn_iterations)
+
+        for k, v in logs.items():
+            self.history.setdefault(k, []).append(v)
+
+        K.set_value(self.model.optimizer.lr, self.clr())
+
diff --git a/deeptricks/learn_rate/clr/__init__.py b/deeptricks/learn_rate/clr/__init__.py
new file mode 100644
index 0000000..ac55561
--- /dev/null
+++ b/deeptricks/learn_rate/clr/__init__.py
@@ -0,0 +1,12 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 22:00
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+from .CyclicLR import CyclicLR
diff --git a/deeptricks/losses/__init__.py b/deeptricks/losses/__init__.py
new file mode 100644
index 0000000..3e1f590
--- /dev/null
+++ b/deeptricks/losses/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 15:12
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/metrics/F1Optimizer.py b/deeptricks/metrics/F1Optimizer.py
new file mode 100644
index 0000000..c5867a8
--- /dev/null
+++ b/deeptricks/metrics/F1Optimizer.py
@@ -0,0 +1,174 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : F1Optimizer
+# @Time         : 2019-09-11 12:03
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+import numpy as np
+import pandas as pd
+import matplotlib.pylab as plt
+from datetime import datetime
+
+'''
+This kernel implements the O(n) F1-Score expectation maximization algorithm presented in
+"Ye, N., Chai, K., Lee, W., and Chieu, H.  Optimizing F-measures: A Tale of Two Approaches. In ICML, 2012."
+
+It solves argmax_(0 <= k <= n,[[None]]) E[F1(P,k,[[None]])]
+with [[None]] being the indicator for predicting label "None"
+given posteriors P = [p_1, p_2, ... , p_n], where p_1 > p_2 > ... > p_n
+under label independence assumption by means of dynamic programming in O(n).
+
+
+c: https://gist.github.com/tkm2261/3f44886b07f87ca953fba3d328ca256b
+'''
+
+
+class F1Optimizer():
+    def __init__(self):
+        pass
+
+    @staticmethod
+    def get_expectations(P, pNone=None):
+        expectations = []
+        P = np.sort(P)[::-1]
+
+        n = np.array(P).shape[0]
+        DP_C = np.zeros((n + 2, n + 1))
+        if pNone is None:
+            pNone = (1.0 - P).prod()
+
+        DP_C[0][0] = 1.0
+        for j in range(1, n):
+            DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]
+
+        for i in range(1, n + 1):
+            DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]
+            for j in range(i + 1, n + 1):
+                DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]
+
+        DP_S = np.zeros((2 * n + 1,))
+        DP_SNone = np.zeros((2 * n + 1,))
+        for i in range(1, 2 * n + 1):
+            DP_S[i] = 1. / (1. * i)
+            DP_SNone[i] = 1. / (1. * i + 1)
+        for k in range(n + 1)[::-1]:
+            f1 = 0
+            f1None = 0
+            for k1 in range(n + 1):
+                f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]
+                f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]
+            for i in range(1, 2 * k - 1):
+                DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]
+                DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]
+            expectations.append([f1None + 2 * pNone / (2 + k), f1])
+
+        return np.array(expectations[::-1]).T
+
+    @staticmethod
+    def maximize_expectation(P, pNone=None):
+        expectations = F1Optimizer.get_expectations(P, pNone)
+
+        ix_max = np.unravel_index(expectations.argmax(), expectations.shape)
+        max_f1 = expectations[ix_max]
+
+        predNone = True if ix_max[0] == 0 else False
+        best_k = ix_max[1]
+
+        return best_k, predNone, max_f1
+
+    @staticmethod
+    def _F1(tp, fp, fn):
+        return 2 * tp / (2 * tp + fp + fn)
+
+    @staticmethod
+    def _Fbeta(tp, fp, fn, beta=1.0):
+        beta_squared = beta ** 2
+        return (1.0 + beta_squared) * tp / ((1.0 + beta_squared) * tp + fp + beta_squared * fn)
+
+
+def print_best_prediction(P, pNone=None):
+    print("Maximize F1-Expectation")
+    print("=" * 23)
+    P = np.sort(P)[::-1]
+    n = P.shape[0]
+    L = ['L{}'.format(i + 1) for i in range(n)]
+
+    if pNone is None:
+        print("Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)")
+        pNone = (1.0 - P).prod()
+
+    PL = ['p({}|x)={}'.format(l, p) for l, p in zip(L, P)]
+    print("Posteriors: {} (n={})".format(PL, n))
+    print("p(None|x)={}".format(pNone))
+
+    opt = F1Optimizer.maximize_expectation(P, pNone)
+    best_prediction = ['None'] if opt[1] else []
+    best_prediction += (L[:opt[0]])
+    f1_max = opt[2]
+
+    print("Prediction {} yields best E[F1] of {}\n".format(best_prediction, f1_max))
+
+
+def save_plot(P, filename='expected_f1.png'):
+    E_F1 = pd.DataFrame(F1Optimizer.get_expectations(P).T, columns=["/w None", "/wo None"])
+    best_k, _, max_f1 = F1Optimizer.maximize_expectation(P)
+
+    plt.style.use('ggplot')
+    plt.figure()
+    E_F1.plot()
+    plt.title('Expected F1-Score for \n {}'.format("P = [{}]".format(",".join(map(str, P)))), fontsize=12)
+    plt.xlabel('k')
+    plt.xticks(np.arange(0, len(P) + 1, 1.0))
+    plt.ylabel('E[F1(P,k)]')
+    plt.plot([best_k], [max_f1], 'o', color='#000000', markersize=4)
+    plt.annotate('max E[F1(P,k)] = E[F1(P,{})] = {:.5f}'.format(best_k, max_f1), xy=(best_k, max_f1),
+                 xytext=(best_k, max_f1 * 0.8), arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=7),
+                 horizontalalignment='center', verticalalignment='top')
+    plt.gcf().savefig(filename)
+
+
+
+def timeit(P):
+    s = datetime.now()
+    F1Optimizer.maximize_expectation(P)
+    e = datetime.now()
+    return (e-s).microseconds / 1E6
+
+
+def benchmark(n=100, filename='runtimes.png'):
+    results = pd.DataFrame(index=np.arange(1,n+1))
+    results['runtimes'] = 0
+
+    for i in range(1,n+1):
+        runtimes = []
+        for j in range(5):
+            runtimes.append(timeit(np.sort(np.random.rand(i))[::-1]))
+        results.iloc[i-1] = np.mean(runtimes)
+
+    x = results.index
+    y = results.runtimes
+    results['quadratic fit'] = np.poly1d(np.polyfit(x, y, deg=2))(x)
+
+    plt.style.use('ggplot')
+    plt.figure()
+    results.plot()
+    plt.title('Expectation Maximization Runtimes', fontsize=12)
+    plt.xlabel('n = |P|')
+    plt.ylabel('time in seconds')
+    plt.gcf().savefig(filename)
+
+
+if __name__ == '__main__':
+    print_best_prediction([0.3, 0.2])
+    print_best_prediction([0.3, 0.2], 0.57)
+    print_best_prediction([0.9, 0.6])
+    print_best_prediction([0.5, 0.4, 0.3, 0.35, 0.33, 0.31, 0.29, 0.27, 0.25, 0.20, 0.15, 0.10])
+    print_best_prediction([0.5, 0.4, 0.3, 0.35, 0.33, 0.31, 0.29, 0.27, 0.25, 0.20, 0.15, 0.10], 0.2)
+
+    save_plot([0.45, 0.35, 0.31, 0.29, 0.27, 0.25, 0.22, 0.20, 0.17, 0.15, 0.10, 0.05, 0.02])
+    benchmark()
\ No newline at end of file
diff --git a/deeptricks/metrics/__init__.py b/deeptricks/metrics/__init__.py
new file mode 100644
index 0000000..691993a
--- /dev/null
+++ b/deeptricks/metrics/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-11 12:02
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/metrics/shake.py b/deeptricks/metrics/shake.py
new file mode 100644
index 0000000..937ef19
--- /dev/null
+++ b/deeptricks/metrics/shake.py
@@ -0,0 +1,44 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : shake
+# @Time         : 2019-09-14 23:27
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+import matplotlib.pyplot as plt
+from tqdm import tqdm
+from sklearn.metrics import roc_auc_score
+from sklearn.model_selection import train_test_split
+import numba
+import numpy as np
+
+
+class Shake(object):
+
+    def __init__(self, oof_preds, y_true, feval=roc_auc_score):
+        self.oof_preds = oof_preds
+        self.y_true = y_true
+        self.feval = feval
+
+    def plot_difference(self, n_splits=100, test_size=0.7):
+        self.cal(n_splits, test_size)
+        self.public_private = np.array(self.metric_public) - np.array(self.metric_private)
+
+        plt.figure(figsize=(10, 6))
+        plt.hist(self.public_private, bins=50)
+        plt.title('(Public - Private) scores')
+        plt.xlabel(f'{self.feval} score difference')
+        plt.show()
+
+    @numba.jit()
+    def cal(self, n_splits=100, test_size=0.7):
+        self.metric_public = []
+        self.metric_private = []
+        for rs in tqdm(range(n_splits)):
+            _ = train_test_split(self.oof_preds, self.y_true, test_size=test_size, random_state=rs)
+            y_preds_public, y_preds_private, y_public, y_private = _
+            self.metric_public.append(self.feval(y_public, y_preds_public))
+            self.metric_private.append(self.feval(y_private, y_preds_private))
diff --git a/deeptricks/models/__init__.py b/deeptricks/models/__init__.py
new file mode 100644
index 0000000..b390673
--- /dev/null
+++ b/deeptricks/models/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2020-02-14 20:40
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/models/fc.py b/deeptricks/models/fc.py
new file mode 100644
index 0000000..2f1cf19
--- /dev/null
+++ b/deeptricks/models/fc.py
@@ -0,0 +1,14 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : Python.
+# @File         : fc
+# @Time         : 2020-03-11 16:46
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+import tensorflow as tf
+from tensorflow.python.keras.layers import \
+    Dense, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout
diff --git a/deeptricks/optimizers/__init__.py b/deeptricks/optimizers/__init__.py
new file mode 100644
index 0000000..3e1f590
--- /dev/null
+++ b/deeptricks/optimizers/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 15:12
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/tricks/Adversarialvalidation.py b/deeptricks/tricks/Adversarialvalidation.py
new file mode 100644
index 0000000..196fcab
--- /dev/null
+++ b/deeptricks/tricks/Adversarialvalidation.py
@@ -0,0 +1,15 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : Adversarialvalidation
+# @Time         : 2019-09-22 21:49
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+"""
+
+https://www.kaggle.com/kevinbonnes/adversarial-validation
+"""
\ No newline at end of file
diff --git a/deeptricks/tricks/CalibratedClassifierCV.py b/deeptricks/tricks/CalibratedClassifierCV.py
new file mode 100644
index 0000000..daffe84
--- /dev/null
+++ b/deeptricks/tricks/CalibratedClassifierCV.py
@@ -0,0 +1,14 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : CalibratedClassifierCV
+# @Time         : 2019-10-09 18:10
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+""""""
+
+from sklearn.calibration import CalibratedClassifierCV
diff --git a/deeptricks/tricks/__init__.py b/deeptricks/tricks/__init__.py
new file mode 100644
index 0000000..5ebe68a
--- /dev/null
+++ b/deeptricks/tricks/__init__.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-19 11:25
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
diff --git a/deeptricks/tricks/online_info/__init__.py b/deeptricks/tricks/online_info/__init__.py
new file mode 100644
index 0000000..b084250
--- /dev/null
+++ b/deeptricks/tricks/online_info/__init__.py
@@ -0,0 +1,50 @@
+"""
+auc> # 
+
+auc
+1/ = 2 * auc - 1  # gini = 2 * auc - 1 gini
+auc<0.5
+
+ > (1 - auc) *  
+#  (1 - auc) *  
+#  auc *    auc
+"""
+
+"""f1
+(f10)f1
+10:  = 2 / f1 - 1
+01:  = ( - 1) / (2 / f1 - 1)  # 
+"""
+
+"""acc
+10:  =  * acc - 1
+01:  =  * acc - 1
+"""
+
+import numpy as np
+
+
+def get_p_n(score, pred):
+    """logloss"""
+    a = - score - np.log(1 - pred)
+    b = np.log(pred / (1 - pred))
+    return a / b
+
+
+def result_scaling(x=0.37, rate_train_true=0.37, rate_test_true=0.165):
+    """log_loss
+    Refer:
+    https://www.kaggle.com/c/quora-question-pairs/discussion/31179
+    https://www.kaggle.com/badat0202/estimate-distribution-of-data-in-lb
+    """
+    a = rate_test_true / rate_train_true
+    b = (1 - rate_test_true) / (1 - rate_train_true)
+    scale_pos_weight = a / b  # scale_pos_weight
+    print("Xgb/Lgb scale_pos_weight: %s" % scale_pos_weight)
+    return a * x / (a * x + b * (1 - x))
+
+
+def get_weight(y):
+    class_weight = dict(enumerate(len(y) / (2 * np.bincount(y))))
+    sample_weight = [class_weight[i] for i in y]
+    return class_weight, sample_weight
diff --git a/deeptricks/tricks/online_info/get_label.py b/deeptricks/tricks/online_info/get_label.py
new file mode 100644
index 0000000..2c6e297
--- /dev/null
+++ b/deeptricks/tricks/online_info/get_label.py
@@ -0,0 +1,32 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+"""
+__title__ = 'get_label'
+__author__ = 'JieYuan'
+__mtime__ = '19-1-28'
+"""
+import numpy as np
+import pandas as pd
+
+
+def get_threshold_or_label(preds, psr, only_return_threshold=False):
+    """: >
+    :param psr: Positive sample ratio
+    :return:
+    """
+    threshold = pd.Series(preds).quantile(1 - psr)
+    if only_return_threshold:
+        return threshold
+    else:
+        return np.where(preds > threshold, 1, 0)
+
+# def threshold_search(y_true, y_proba):
+#     best_threshold = 0
+#     best_score = 0
+#     for threshold in tqdm([i * 0.01 for i in range(100)]):
+#         score = f1_score(y_true=y_true, y_pred=y_proba > threshold)
+#         if score > best_score:
+#             best_threshold = threshold
+#             best_score = score
+#     search_result = {'threshold': best_threshold, 'f1': best_score}
+#     return search_result
diff --git a/deeptricks/utils/__init__.py b/deeptricks/utils/__init__.py
new file mode 100644
index 0000000..86f4095
--- /dev/null
+++ b/deeptricks/utils/__init__.py
@@ -0,0 +1,16 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : __init__.py
+# @Time         : 2019-09-10 14:48
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  :
+import numpy as np
+from .cprint import cprint
+from .timer import timer
+
+
+def noramlize(x):
+    return x / np.linalg.norm(x, 2, axis=len(x.shape) > 1, keepdims=True)
diff --git a/deeptricks/utils/cprint.py b/deeptricks/utils/cprint.py
new file mode 100644
index 0000000..f0d6522
--- /dev/null
+++ b/deeptricks/utils/cprint.py
@@ -0,0 +1,41 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : cprint
+# @Time         : 2020-02-12 00:09
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+def cprint(string='Hello World !', bg='blue', fg='', mode=1, return_str=False):
+    """
+    :param s: string
+    :param fg/bg: foreground/background
+        'black', 'red', 'green', 'yellow', 'blue', 'purple', 'cyan', 'white'
+    :param mode:
+        0
+        1
+        22
+        4
+        24
+        5
+        25
+        7
+        27
+        https://www.cnblogs.com/hellojesson/p/5961570.html
+    :return:
+    """
+    colors = ['green', 'yellow', 'black', 'cyan', 'blue', 'red', 'white', 'purple']
+    fc = dict(zip(colors, range(40, 97)))
+    bc = dict(zip(colors, range(90, 97)))
+    _ = f"\033[{mode};{fc[fg]};{bc[bg]}m{string}\033[0m" if fg else f"\033[{mode};{bc[bg]}m{string}\033[0m"
+    if return_str:
+        return _
+    else:
+        print(_)
+
+
+if __name__ == '__main__':
+    cprint()
diff --git a/deeptricks/utils/timer.py b/deeptricks/utils/timer.py
new file mode 100644
index 0000000..b56a54c
--- /dev/null
+++ b/deeptricks/utils/timer.py
@@ -0,0 +1,40 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : timer
+# @Time         : 2020-02-12 00:05
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  :
+    # class MyResource:
+    #     def query(self):
+    #         print('query data')
+    #
+    # @contextmanager
+    # def make_myresource():
+    #     print('start to connect')
+    #     yield MyResource()
+    #     print('end connect')
+    #     pass
+    # with make_myresource() as r:
+    #      r.query()
+from skorch.helper import parse_args
+
+import time
+from contextlib import contextmanager
+from deeptricks.utils import cprint
+
+@contextmanager
+def timer(task_name="timer"):
+    print('\n')
+    cprint(f" {task_name} started")
+    t0 = time.time()
+    yield
+    cprint(f" {task_name} done in {time.time() - t0:.3f} seconds")
+
+
+if __name__ == '__main__':
+    with timer() as t:
+        print('xxx')
+
diff --git a/deeptricks/utils/torch_.py b/deeptricks/utils/torch_.py
new file mode 100644
index 0000000..34b0a5b
--- /dev/null
+++ b/deeptricks/utils/torch_.py
@@ -0,0 +1,13 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : DeepTricks.
+# @File         : torch
+# @Time         : 2020-02-20 18:19
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+import torch
+
diff --git a/pypi.sh b/pypi.sh
new file mode 100755
index 0000000..3051ad6
--- /dev/null
+++ b/pypi.sh
@@ -0,0 +1,4 @@
+#!/usr/bin/env bash
+python setup.py sdist bdist_wheel && twine upload ./dist/*
+rm -rf ./build/ ./dist/ ./*.egg-info/
+exit
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
new file mode 100644
index 0000000..e27dbf9
--- /dev/null
+++ b/requirements.txt
@@ -0,0 +1,2 @@
+tqdm
+wrapt
\ No newline at end of file
diff --git a/setup.py b/setup.py
new file mode 100644
index 0000000..d597794
--- /dev/null
+++ b/setup.py
@@ -0,0 +1,65 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+# @Project      : tql-Python.
+# @File         : setup
+# @Time         : 2019-06-17 16:12
+# @Author       : yuanjie
+# @Email        : yuanjie@xiaomi.com
+# @Software     : PyCharm
+# @Description  : 
+
+
+import os
+import time
+from setuptools import find_packages, setup
+
+# rename
+package_name = 'DeepTricks'
+project_name = 'DeepTricks'
+version = time.strftime("%Y.%m.%d.%H.%M.%S", time.localtime())
+
+with open("README.md", encoding='utf-8') as f:
+    long_description = f.read()
+
+
+def get_requirements():
+    _ = './requirements.txt'
+    if os.path.isfile(_):
+        with open(_, encoding='utf-8') as f:
+            return f.read().split()
+
+
+setup(
+    name=package_name,
+    version=version,
+    url='https://github.com/Jie-Yuan/' + project_name,
+    keywords=["tool wheel", "yuanjie", 'utils'],
+    description=('description'),
+    long_description=long_description,
+    long_description_content_type="text/markdown",
+    author='JieYuan',
+    author_email='313303303@qq.com',
+    maintainer='JieYuan',
+    maintainer_email='313303303@qq.com',
+    license='MIT',
+    packages=find_packages(),
+    include_package_data=True,
+    package_data={'': ['*.*']},
+    platforms=["all"],
+    python_requires='>=3.5',
+    classifiers=[
+
+        'Operating System :: OS Independent',
+        'Intended Audience :: Developers',
+        'License :: OSI Approved :: MIT License',
+
+        'Programming Language :: Python',
+        'Programming Language :: Python :: Implementation',
+    ],
+
+    install_requires=get_requirements(),
+
+    entry_points={'console_scripts': [
+        'tql-cli=tql.utils.cli:cli'
+    ]}
+)
